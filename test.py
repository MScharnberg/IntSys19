"""Test

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/MScharnberg/IntSys19/blob/master/Test.ipynb

# Testing

Intelligent Systems

---

[@mats.scharnberg](mailto:mats.scharnberg@study.hs-duesseldorf.de)

[@christoph.schneider](mailto:christoph.schneider@study.hs-duesseldorf.de)

[@tobias.vossen](mailto:tobias.vossen@study.hs-duesseldorf.de)

## Contents

* Setup
* Data
* Model
* Deployment

## Setup

### Requirements"""

import shutil

import numpy as np
print('NumPy version:', np.__version__)

from matplotlib import pyplot as plt

from tensorboard import version
print('TensorBoard version:', version.VERSION)
from tensorboard.plugins.hparams import api as hp

import tensorflow as tf
print('TensorFlow version:', tf.__version__)
from tensorflow import keras

import tensorflow_datasets as tfds
print('TensorFlow Datasets version:', tfds.__version__)

"""## Data

*   Load dataset
*   Explore dataset
*   Preprocess dataset
*   Visualize dataset

### Constants
"""

_BS = 32 #@param {type:"slider", min:16, max:64, step:16}
_DIM = 28 #@param ["28"] {type:"raw"}
_DS = 'mnist'
_INPUT = 196 # Noise input
_SHAPE = (_DIM, _DIM, 1) # Image shape
_SIZE = '[:100%]' # Dataset size

"""### Load dataset"""

def load_dataset(dataset):
  """Load dataset by means of TFDS (TensorFlow Datasets)
  
  Args:
    dataset: String
  
  Returns:
    train: tf.data.Dataset
    test: tf.data.Dataset
  """

  (_, test), info = tfds.load(dataset,
                            split=['train'+_SIZE, 'test'+_SIZE],
                            as_supervised=True,
                            with_info=True)

  print('Description:', info.description)
  print('Source:', info.homepage)
  print('Total number of test examples:', info.splits['test'].num_examples)
  return test

test_dataset = load_dataset(_DS)

"""### Preprocess dataset"""

def normalize(image, label):
  """Normalize dataset 
  
  Normalize:
    Cast -> Normalize

  Args:
    image: tf.Tensor as Integer
    label: tf.Tensor as Integer
  
  Returns:
    image: tf.Tensor as Float
    label: tf.Tensor as Float
    noise: tf.Tensor as Float
  """

  image = tf.cast(image, tf.float32)
  image = (image - 127.5) / 127.5 # -1...1
  
  label = tf.cast(label, tf.float32) # (1)
  label = tf.expand_dims(label, -1)

  noise = tf.random.uniform((_INPUT, )) # (196)

  return image, label, noise

def preprocess(dataset, shuffle=True, batch=True, prefetch=False):
  """Preprocess dataset

  Preprocess: 
    Normalize -> Shuffle -> Batch -> Prefetch
  
  Args:
    dataset: tf.data.Dataset
    shuffle: boolean
    batch: boolean
    prefetch: boolean
  
  Returns:
    dataset: tf.data.Dataset
  """

  dataset = dataset.map(normalize)
  if shuffle: dataset = dataset.shuffle(tf.data.experimental.cardinality(dataset))
  if batch: dataset = dataset.batch(_BS, drop_remainder=True)
  if prefetch: dataset = dataset.prefetch(1)

  return dataset

test_dataset = preprocess(test_dataset)

"""### Visualize dataset"""

def visualize(dataset):
  """Visualize dataset
  
  Args:
    dataset: tf.data.Dataset
  """

  dataset = dataset.unbatch()
  fig = plt.figure(figsize=(8, 8))
  i = 0
  for image, label, noise in dataset.take(16):
    fig.add_subplot(4, 4, i+1)
    plt.imshow(tf.squeeze(image), cmap='gray')
    plt.title(int(label.numpy()))
    plt.axis('off')
    i = i+1

  plt.suptitle('Real data instances')
  plt.show()

visualize(test_dataset)

"""## Model

*   Get model
*   Explore model
*   Evaluate model

### Parameters
"""

_INPUT = 196 # Generator input

"""### Get model"""

generator_path = keras.utils.get_file('generator.h5', 'https://github.com/MScharnberg/IntSys19/blob/master/model/generator.h5?raw=true', cache_subdir='model')
shutil.move(generator_path, './generator.h5')

discriminator_path = keras.utils.get_file('discriminator.h5', 'https://github.com/MScharnberg/IntSys19/blob/master/model/discriminator.h5?raw=true', cache_subdir='model')
shutil.move(discriminator_path, './discriminator.h5')

"""### Explore model"""

generator = keras.models.load_model('generator.h5')
generator.summary()

discriminator = keras.models.load_model('discriminator.h5')
discriminator.summary()

"""## Deployment

*   Use model

### Use model
"""

def generate_multiple():
  """Generate multiple digits

  Args:
    num: Integer
  """

  fig = plt.figure(figsize=(8, 8))

  for i in range(16):
    fig.add_subplot(4, 4, i+1)
    input_vector = tf.random.normal((1, _INPUT))
    image = generator(input_vector, training=False)
    plt.imshow(tf.squeeze(image), cmap='gray')
    plt.axis('off')

  plt.suptitle('Fake data instances')
  plt.show()

generate_multiple()